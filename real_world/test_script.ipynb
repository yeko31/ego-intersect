{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mb syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.2367\n",
      "Precision    : 0.6862\n",
      "Recall       : 0.9149\n",
      "F1 Score     : 0.7842\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vector = [int(x) for x in subfolder.split('_')]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                    self.images.append(os.path.join(sub_path,fname))\n",
    "                    self.labels.append(label_vector)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"mobilenetv2\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "mobilenet_nf = build_model(\"mobilenetv2\", mobilenet_weights, pretrained=False)\n",
    "evaluate_model(mobilenet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rn syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.2500\n",
      "Precision    : 0.6667\n",
      "Recall       : 0.9362\n",
      "F1 Score     : 0.7788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vec = [int(x) for x in subfolder.split(\"_\")]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.images.append(os.path.join(sub_path, fname))\n",
    "                    self.labels.append(label_vec)\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"resnet50\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "resnet_nf = build_model(\"resnet50\", resnet_weights, pretrained=False)\n",
    "evaluate_model(resnet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.2233\n",
      "Precision    : 0.6968\n",
      "Recall       : 0.9291\n",
      "F1 Score     : 0.7964\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vec = [int(x) for x in subfolder.split(\"_\")]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.images.append(os.path.join(sub_path, fname))\n",
    "                    self.labels.append(label_vec)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"mobilenetv2\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "mobilenet_nf = build_model(\"mobilenetv2\", mobilenet_weights, pretrained=False)\n",
    "evaluate_model(mobilenet_nf, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rn_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.0767\n",
      "Precision    : 0.8831\n",
      "Recall       : 0.9645\n",
      "F1 Score     : 0.9220\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vector = [int(x) for x in subfolder.split('_')]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                    self.images.append(os.path.join(sub_path,fname))\n",
    "                    self.labels.append(label_vector)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"resnet50\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "resnet_nf = build_model(\"resnet50\", resnet_weights, pretrained=False)\n",
    "evaluate_model(resnet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mb_All_lay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.2367\n",
      "Precision    : 0.6733\n",
      "Recall       : 0.9645\n",
      "F1 Score     : 0.7930\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vector = [int(x) for x in subfolder.split('_')]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                    self.images.append(os.path.join(sub_path,fname))\n",
    "                    self.labels.append(label_vector)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"mobilenetv2\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "mobilenet_nf = build_model(\"mobilenetv2\", mobilenet_weights, pretrained=False)\n",
    "evaluate_model(mobilenet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r_net_all_lay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.2067\n",
      "Precision    : 0.7484\n",
      "Recall       : 0.8440\n",
      "F1 Score     : 0.7933\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vec = [int(x) for x in subfolder.split(\"_\")]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.images.append(os.path.join(sub_path, fname))\n",
    "                    self.labels.append(label_vec)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"resnet50\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "resnet_nf = build_model(\"resnet50\", resnet_weights, pretrained=False)\n",
    "evaluate_model(resnet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rn he_inint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.2200\n",
      "Precision    : 0.7820\n",
      "Recall       : 0.7376\n",
      "F1 Score     : 0.7591\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vec = [int(x) for x in subfolder.split(\"_\")]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.images.append(os.path.join(sub_path, fname))\n",
    "                    self.labels.append(label_vec)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"resnet50\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "resnet_nf = build_model(\"resnet50\", resnet_weights, pretrained=False)\n",
    "evaluate_model(resnet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fan_in_He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intellisense08/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation =====\n",
      "Hamming Loss : 0.1933\n",
      "Precision    : 0.7456\n",
      "Recall       : 0.8936\n",
      "F1 Score     : 0.8129\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import hamming_loss, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "test_dir = \"\"   # <-- your test folder\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = [\"left\", \"right\", \"forward\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "mobilenet_weights = \"\"\n",
    "resnet_weights    = \"\"\n",
    "\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            sub_path = os.path.join(root_dir, subfolder)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                continue\n",
    "            label_vec = [int(x) for x in subfolder.split(\"_\")]\n",
    "            for fname in os.listdir(sub_path):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.images.append(os.path.join(sub_path, fname))\n",
    "                    self.labels.append(label_vec)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # expand grayscale → 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# -------------------- Transforms --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = MultiLabelDataset(test_dir, transform=transform)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------- Model Builder --------------------\n",
    "def build_model(arch=\"resnet50\", weight_path=None, pretrained=True):\n",
    "    if arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported arch\")\n",
    "\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "def evaluate_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds  = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(f\"Hamming Loss : {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision    : {precision_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Recall       : {recall_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"F1 Score     : {f1_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- Draw & Save Predictions --------------------\n",
    "def save_predictions_with_overlay(model, loader, arch_name, save_root=\"test_predictions\", threshold=0.5):\n",
    "    model.eval()\n",
    "    save_dir = os.path.join(save_root, arch_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) >= threshold).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                pred_vec = preds[i]\n",
    "                label_vec = labels[i]\n",
    "\n",
    "                pred_classes = [class_names[j] for j, v in enumerate(pred_vec) if v == 1]\n",
    "                true_classes = [class_names[j] for j, v in enumerate(label_vec) if v == 1]\n",
    "\n",
    "                pred_text = \"Pred: \" + (\",\".join(pred_classes) if pred_classes else \"None\")\n",
    "                true_text = \"True: \" + (\",\".join(true_classes) if true_classes else \"None\")\n",
    "\n",
    "                img_path = loader.dataset.images[batch_idx * loader.batch_size + i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (400, 400))\n",
    "                cv2.putText(img, pred_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                cv2.putText(img, true_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"overlay_{os.path.basename(img_path)}\")\n",
    "                cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"Overlay predictions saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained=False\n",
    "resnet_nf = build_model(\"resnet50\", resnet_weights, pretrained=False)\n",
    "evaluate_model(resnet_nf, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
